# -*- coding: utf-8 -*-
"""AML_SEE_LPW.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IKMwNC_vxrHZZKH-Xvw_-o-AmbaJpsa1

## Step 1: Mount Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Step 2: Load and Parse the Raw Dataset"""

import pandas as pd
import numpy as np

file_path = '/content/drive/My Drive/Colab Notebooks/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt'

data = []
with open(file_path) as f:
    for line in f:
        try:
            parts = line.strip().split(',')
            if len(parts) >= 6:
                user_id, activity, timestamp, x, y, z = parts[0], parts[1], parts[2], float(parts[3]), float(parts[4]), float(parts[5].split(';')[0])
                data.append([user_id, activity, timestamp, x, y, z])
        except:
            continue

columns = ['user', 'activity', 'timestamp', 'x', 'y', 'z']
df = pd.DataFrame(data, columns=columns)
print(df.head())

df

"""## Step 3: Feature Extraction via Sliding Window"""

def extract_features(df, window_size=200):
    X, y = [], []
    for i in range(0, len(df) - window_size, window_size):
        window = df.iloc[i:i+window_size]
        x_vals = window['x'].values
        y_vals = window['y'].values
        z_vals = window['z'].values

        features = []
        for axis in [x_vals, y_vals, z_vals]:
            features += [
                np.mean(axis), np.std(axis), np.min(axis), np.max(axis),
                np.median(axis), np.percentile(axis, 25), np.percentile(axis, 75)
            ]
        label = window['activity'].mode()[0]
        X.append(features)
        y.append(label)
    return np.array(X), np.array(y)

X, y = extract_features(df)
print("Shape of X (Number of samples, Number of features per sample) = ",X.shape)
print("Shape of Y (Number of labels) = ",y.shape)

"""## Step 4: Encode Labels and Train-Test Split"""

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
y_encoded = le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

"""## Step 5: Train Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=le.classes_))

"""## Step 6: Visualization of Classification Results"""

## Step 6: Visualization of Classification Results

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_,
            yticklabels=le.classes_)

plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()