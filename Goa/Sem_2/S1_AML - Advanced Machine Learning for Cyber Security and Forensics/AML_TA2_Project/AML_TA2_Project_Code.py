# -*- coding: utf-8 -*-
"""NLP_TA2_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YgqR6DplHggogXh2Wv46ocIJAHjUVnSG

# TA2: Marathi Handwriting/Text Recognition using Transformer-based OCR + NLP

## Steps to Follow:

> 1. **Capture or upload** an image of a handwritten page written in your mother tongue.

> 2. **Preprocess the image** to improve clarity (e.g., convert to grayscale, resize, denoise).

> 3.  **Use OCR** to extract text from the image (e.g., Transformer based OCR with language pack for your language).

> 4. **Normalize** the extracted text (remove noise, unwanted characters, fix encoding issues).

> 5. **Tokenize** the text using an appropriate NLP tokenizer for your language.

> 6. **Marathi Named Entity Recognition (NER)**, Perform Named Entity Recognition on the extracted Marathi text to identify entities such as names of people, places, organizations, dates, etc.

> 7. **Performing NLP task**, such as:
>    - Language detection
>    - Translation

> 8. **Display the final output** in a readable format (console, notebook cell, or GUI).

> 9. **Sentiment Analysis:**  
   Analyze the sentiment (positive, negative, or neutral) of the text extracted through OCR to understand the emotional tone of the content.


> 10. **Summarization** of the extracted text

### Step 0: Install & Import Required Libraries
"""

# Install All Required Python Libraries

!pip install gdown
!pip install indic-nlp-library
!pip install pytesseract
!pip install opencv-python-headless
!pip install googletrans==4.0.0-rc1
!pip install deep-translator
!pip install langdetect

# Update and Install All Required Libraries and Tools

!sudo apt-get update
!sudo apt-get upgrade
!sudo apt-get install -y tesseract-ocr
!sudo apt-get install -y tesseract-ocr-mar
!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git

# Import All Required Libraries

import gdown
from google.colab import files
from PIL import Image
import numpy as np
import cv2
import torch
import pytesseract
import re
import pandas as pd
import matplotlib.pyplot as plt
from deep_translator import GoogleTranslator
from indicnlp.tokenize.indic_tokenize import trivial_tokenize
from langdetect import detect

!huggingface-cli clear-cache
from huggingface_hub import login
login()

"""### Step 1: Upload Image"""

# Option for the user to try dynamic upload quickly
user_choice = input("Would you like to skip static image and upload a dynamic image? (y/n) [default: n]: ").strip().lower()

if user_choice == 'y':
    print("Proceeding with dynamic image upload...")
    # Dynamic Image Uploads
    uploaded = files.upload()  # Upload image from user
    filename = list(uploaded.keys())[0]  # Get the name of the uploaded file

    # Open image with PIL
    img_pil = Image.open(filename)
    img_pil.show()

else:
    # Static Image Uploads
    file_id = '1z526YFcKb2g8HftFLPhH9Gg25I-jNtHh'  # Extract the file ID from the shared link
    url = f'https://drive.google.com/uc?export=download&id={file_id}'

    try:
        # Try downloading the static image using gdown
        gdown.download(url, 'marathi.gif', quiet=False)

        # Open the image with PIL
        img_pil = Image.open('marathi.gif')
        img_pil.show()

    except Exception as e:
        # If static image download fails, handle with dynamic image upload
        print(f"Static image download failed with error: {e}")
        print("Proceeding with dynamic image upload...")

        # Dynamic Image Uploads
        uploaded = files.upload()  # Upload image from user
        filename = list(uploaded.keys())[0]  # Get the name of the uploaded file

        # Open image with PIL
        img_pil = Image.open(filename)
        img_pil.show()

"""### Step 2: Preprocess Image"""

# Convert PIL to OpenCV format
img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# Preprocess image
gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
blurred = cv2.GaussianBlur(gray, (3, 3), 0)
_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

#Show the preprocessed image
plt.imshow(thresh, cmap='gray')
plt.title("Preprocessed Image")
plt.axis('off')
plt.show()

"""### Step 3: Transformer based OCR Extraction

#### TrOCR
"""

from transformers import TrOCRProcessor, VisionEncoderDecoderModel

# Load the pre-trained TrOCR model and processor
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")
model.eval()  # inference mode only

# Optional: use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Step 1: Load or convert the image
# If using OpenCV image (NumPy array), convert to PIL
if isinstance(img_pil, np.ndarray):
    img_pil_ = Image.fromarray(img_pil)

# Step 2: Preprocess (resize and RGB)
img_pil_ = img_pil.convert("RGB")
img_pil_ = img_pil_.resize((384, 384))

# Step 3: Feature extraction
pixel_values = processor(images=img_pil_, return_tensors="pt").pixel_values.to(device)

# Step 4: Generate text from image
with torch.no_grad():
    generated_ids = model.generate(pixel_values)
    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

print("\nüìù OCR Text with TrOCR:\n", generated_text)

"""#### Abhi964/MahaPhrase_mahaBERTv2_Finetuning"""

# Use pytesseract for raw text
ocr_text = pytesseract.image_to_string(thresh, lang="mar")

# Run through l3cube-pune/marathi-bert-v2 for context-aware prediction
from transformers import pipeline
ocr_model = pipeline("text-classification", model="Abhi964/MahaPhrase_mahaBERTv2_Finetuning", tokenizer="Abhi964/MahaPhrase_mahaBERTv2_Finetuning")
ocr_result = ocr_model(ocr_text)

print("\nüìú OCR Text:\n", ocr_text)
print("\nüîç MahaBERT Inference:\n", ocr_result)

"""### Step 4: Normalize Text"""

# Normalize the OCR output
normalized_text = re.sub(r'[^\u0900-\u097F\s]', '', ocr_text)
normalized_text = re.sub(r'\s+', ' ', normalized_text).strip()
print("\nNormalized Marathi Text:\n", normalized_text)

"""### Step 5: Tokenization"""

# Tokenization

# Simple whitespace tokenizer
tokens_simple = normalized_text.split()
print("\nTokenized Words (Simple Split):\n", tokens_simple)

# Advanced Indic NLP tokenizer
tokens_advanced = trivial_tokenize(normalized_text, lang='mar')
print("\nTokenized Words (Indic NLP):\n", tokens_advanced)

tokens = tokens_advanced

"""### Step 6: Name Entity Recogination"""

# NER Marathi

# Use a pipeline as a high-level helper
from transformers import pipeline
pipe = pipeline("token-classification", model="l3cube-pune/marathi-mixed-ner-iob")

ner_results = pipe(normalized_text)
print("\nNER Results:\n", ner_results)

"""### Step 7: Language Detection and Translation

#### Language Detection
"""

# Detect language
detected_language_code = detect(normalized_text)

# Map language code to full name (optional, for readability)
language_map = {
    'mr': 'Marathi',
    'en': 'English',
    # Add more mappings as needed
}
detected_language = language_map.get(detected_language_code, detected_language_code)

# Print result
print(f"Detected language: {detected_language}")

"""#### Translation"""

# Convert Marathi numbers to English numbers in text and tokens
devanagari_to_english_digits = {
    '‡•¶': '0', '‡•ß': '1', '‡•®': '2', '‡•©': '3', '‡•™': '4',
    '‡•´': '5', '‡•¨': '6', '‡•≠': '7', '‡•Æ': '8', '‡•Ø': '9'
}

def convert_devanagari_numbers(text):
    return re.sub(r'[\u0966-\u096F]+', lambda m: ''.join(devanagari_to_english_digits.get(ch, ch) for ch in m.group()), text)

# Translate full text
normalized_with_english_digits = convert_devanagari_numbers(normalized_text)
translation_text = GoogleTranslator(source='mr', target='en').translate(normalized_with_english_digits)
print("\nEnglish Translated Text:\n", translation_text)

# Translate individual tokens
translated_tokens = []
for token in tokens:
    if re.fullmatch(r'[\u0966-\u096F]+', token):
        translated_tokens.append(convert_devanagari_numbers(token))
    else:
        try:
            translated = GoogleTranslator(source='mr', target='en').translate(token)
            translated_tokens.append(translated)
        except:
            translated_tokens.append(token)

print("\nTranslated Tokens:\n", translated_tokens)

"""### Step 8: Final Output"""

# Display the image
plt.imshow(img_pil)
plt.axis('off')
plt.title("Uploaded Image")
plt.show()

# Final Output
print("\nFinal Output Summary:\n")
print("Original Marathi OCR Text:\n", normalized_text) # OCR Marathi Text
print("\nMarathi to English Translation:\n", translation_text) # English Translated Text
print("\nTokens in Marathi:\n", tokens) # Marathi Tokens
print("\nTranslated Tokens in English:\n", translated_tokens) # English Tokens

# Show tokens in tabular format
df = pd.DataFrame({'Marathi': tokens, 'English': translated_tokens})
df

"""### Step 9: Sentiment Analysis"""

# Sentiment Analysis

from transformers import pipeline

try:
    # Try Marathi sentiment analysis model (if available)
    sentiment_pipeline = pipeline("sentiment-analysis", model="l3cube-pune/MarathiSentiment")
    sentiment_result = sentiment_pipeline(normalized_text)
    print("\nMarathi Sentiment Analysis Result:\n", sentiment_result)

except:
    print("\nMarathi sentiment model failed or not available. Falling back to English sentiment analysis.")

    try:
        # Fallback: Use English-translated text and English sentiment model
        en_sentiment_pipeline = pipeline("sentiment-analysis")
        sentiment_result = en_sentiment_pipeline(translation_text)
        print("\nEnglish Sentiment Analysis Result:\n", sentiment_result)

    except Exception as e:
        print("\nSentiment analysis failed due to:", str(e))

"""### Step 10: Summarize the Marathi and English text"""

# Summarization using transformers pipeline
summarizer_mar = pipeline("summarization", model="Existance/mT5_multilingual_XLSum-marathi-summarization")
summarizer_en = pipeline("summarization", model="Falconsai/text_summarization")

try:
    marathi_summary = summarizer_mar(normalized_text, max_length=130, min_length=30, do_sample=False)
    print("\nMarathi Text Summary:\n", marathi_summary[0]["summary_text"])
except Exception as e:
    print(f"\nError summarizing Marathi text: {e}")

try:
    english_summary = summarizer_en(translation_text, max_length=130, min_length=30, do_sample=False)
    print("\nEnglish Text Summary:\n", english_summary[0]["summary_text"])
except Exception as e:
    print(f"\nError summarizing English text: {e}")